{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这些模块和包都是在逐步的探索中所需要的，然后全部汇总到这里，\n",
    "#    并不是一开始就知道了 ^_^ ^_^ ^_^\n",
    "# 1、导入模块和包\n",
    "import pandas as pd    # 加载并处理csv文件\n",
    "import datetime        # 利用datetime处理时间戳\n",
    "import _pickle as cPickle    # 数据以二进制进行高效的储存到文件\n",
    "from collections import defaultdict     # 利用Python设置稀疏矩阵的NULL位置的默认值\n",
    "import scipy.sparse as ss     # 利用scipy构建稀疏矩阵\n",
    "import scipy.io as sio    # 利用scipy储存评分矩阵\n",
    "import numpy as np    # 利用numpy创建指定长度或形状的矩阵以及矩阵运算\n",
    "from numpy.random import random    # numpy.random中的randn函数生成一些正态分布的随机数据\n",
    "import time    # 利用Python内置模块，计算训练时迭代的时间\n",
    "import json    # 将模型参数保存为json文件，加载模型参数json文件\n",
    "import scipy    # 将储存加载的稀疏评分矩阵转换为numpy矩阵形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.1、LMF模型\n",
    "\n",
    "# ##########################\n",
    "#\n",
    "# 核心算法实现\n",
    "#\n",
    "# @输入参数\n",
    "#     R —— M*N 评分矩阵\n",
    "#     k —— 隐向量的维度\n",
    "#     theta —— 迭代次数\n",
    "#     alpha —— 步长（学习率）\n",
    "#     lamda —— 正则化系数\n",
    "#\n",
    "# @输出参数\n",
    "#     分解之后的 P，Q\n",
    "#     P：初始化用户特征矩阵 M*K\n",
    "#     Q：初始化物品特征矩阵 N*K\n",
    "#\n",
    "# ##########################\n",
    "\n",
    "# 设定模型参数\n",
    "K = 5\n",
    "theta = 100\n",
    "alpha = 0.0002\n",
    "lamda = 0.004\n",
    "\n",
    "# 核心算法\n",
    "def LFM_grad_desc( R, K, theta, alpha, lamda ):\n",
    "    # 基本维度参数定义\n",
    "    M = R.shape[0]\n",
    "    N = R.shape[1]\n",
    "    \n",
    "    # P,Q初始值，随机生成\n",
    "    P = np.random.rand(M, K)\n",
    "    Q = np.random.rand(N, K)\n",
    "    Q = Q.T\n",
    "    \n",
    "    # 开始迭代\n",
    "    for step in range(theta):\n",
    "        print(\"开始第{}次迭代训练\".format(step))\n",
    "        # 对所有的用户u、物品i做遍历，对应的特征向量Pu、Qi梯度下降\n",
    "        for u in range(M):\n",
    "            for i in range(N):\n",
    "                # 对于每一个大于0的评分，求出预测评分误差\n",
    "                if R[u, i] > 0:\n",
    "                    eui = np.dot( P[u,:], Q[:,i] ) - R[u, i]\n",
    "                    \n",
    "                    # 代入公式，按照梯度下降算法更新当前的Pu、Qi\n",
    "                    for k in range(K):\n",
    "                        P[u][k] = P[u][k] - alpha * ( 2 * eui * Q[k][i] + 2 * lamda * P[u][k] )\n",
    "                        Q[k][i] = Q[k][i] - alpha * ( 2 * eui * P[u][k] + 2 * lamda * Q[k][i] )\n",
    "        \n",
    "        # u、i遍历完成，所有特征向量更新完成，可以得到P、Q，可以计算预测评分矩阵\n",
    "        predR = np.dot( P, Q )\n",
    "        \n",
    "        # 计算当前损失函数\n",
    "        cost = 0\n",
    "        for u in range(M):\n",
    "            for i in range(N):\n",
    "                if R[u, i] > 0:\n",
    "                    cost += ( np.dot( P[u,:], Q[:,i] ) - R[u, i] ) ** 2\n",
    "                    # 加上正则化项\n",
    "                    for k in range(K):\n",
    "                        cost += lamda * ( P[u][k] ** 2 + Q[k, i] ** 2 )\n",
    "        print(\"第{}次迭代结束\".format(step))\n",
    "        if cost < 0.0001:\n",
    "            break\n",
    "        \n",
    "    return P, Q.T, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrix"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载评分矩阵\n",
    "data_path = \"./dataset/ml-25m/\"\n",
    "user_item_score = sio.mmread(data_path + \"user_item_score\")\n",
    "# todense() 转换为矩阵 numpy \n",
    "R = scipy.sparse.csc_matrix.todense(user_item_score)\n",
    "type(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第0次迭代训练\n",
      "第0次迭代结束\n",
      "开始第1次迭代训练\n",
      "第1次迭代结束\n",
      "开始第2次迭代训练\n",
      "第2次迭代结束\n",
      "开始第3次迭代训练\n",
      "第3次迭代结束\n",
      "开始第4次迭代训练\n",
      "第4次迭代结束\n",
      "开始第5次迭代训练\n",
      "第5次迭代结束\n",
      "开始第6次迭代训练\n",
      "第6次迭代结束\n",
      "开始第7次迭代训练\n",
      "第7次迭代结束\n",
      "开始第8次迭代训练\n",
      "第8次迭代结束\n",
      "开始第9次迭代训练\n",
      "第9次迭代结束\n",
      "开始第10次迭代训练\n",
      "第10次迭代结束\n",
      "开始第11次迭代训练\n",
      "第11次迭代结束\n",
      "开始第12次迭代训练\n",
      "第12次迭代结束\n",
      "开始第13次迭代训练\n",
      "第13次迭代结束\n",
      "开始第14次迭代训练\n",
      "第14次迭代结束\n",
      "开始第15次迭代训练\n",
      "第15次迭代结束\n",
      "开始第16次迭代训练\n",
      "第16次迭代结束\n",
      "开始第17次迭代训练\n",
      "第17次迭代结束\n",
      "开始第18次迭代训练\n",
      "第18次迭代结束\n",
      "开始第19次迭代训练\n",
      "第19次迭代结束\n",
      "开始第20次迭代训练\n",
      "第20次迭代结束\n",
      "开始第21次迭代训练\n",
      "第21次迭代结束\n",
      "开始第22次迭代训练\n",
      "第22次迭代结束\n",
      "开始第23次迭代训练\n",
      "第23次迭代结束\n",
      "开始第24次迭代训练\n",
      "第24次迭代结束\n",
      "开始第25次迭代训练\n",
      "第25次迭代结束\n",
      "开始第26次迭代训练\n",
      "第26次迭代结束\n",
      "开始第27次迭代训练\n",
      "第27次迭代结束\n",
      "开始第28次迭代训练\n",
      "第28次迭代结束\n",
      "开始第29次迭代训练\n",
      "第29次迭代结束\n",
      "开始第30次迭代训练\n",
      "第30次迭代结束\n",
      "开始第31次迭代训练\n",
      "第31次迭代结束\n",
      "开始第32次迭代训练\n",
      "第32次迭代结束\n",
      "开始第33次迭代训练\n",
      "第33次迭代结束\n",
      "开始第34次迭代训练\n",
      "第34次迭代结束\n",
      "开始第35次迭代训练\n",
      "第35次迭代结束\n",
      "开始第36次迭代训练\n",
      "第36次迭代结束\n",
      "开始第37次迭代训练\n",
      "第37次迭代结束\n",
      "开始第38次迭代训练\n",
      "第38次迭代结束\n",
      "开始第39次迭代训练\n",
      "第39次迭代结束\n",
      "开始第40次迭代训练\n",
      "第40次迭代结束\n",
      "开始第41次迭代训练\n",
      "第41次迭代结束\n",
      "开始第42次迭代训练\n",
      "第42次迭代结束\n",
      "开始第43次迭代训练\n",
      "第43次迭代结束\n",
      "开始第44次迭代训练\n",
      "第44次迭代结束\n",
      "开始第45次迭代训练\n",
      "第45次迭代结束\n",
      "开始第46次迭代训练\n",
      "第46次迭代结束\n",
      "开始第47次迭代训练\n",
      "第47次迭代结束\n",
      "开始第48次迭代训练\n",
      "第48次迭代结束\n",
      "开始第49次迭代训练\n",
      "第49次迭代结束\n",
      "开始第50次迭代训练\n",
      "第50次迭代结束\n",
      "开始第51次迭代训练\n",
      "第51次迭代结束\n",
      "开始第52次迭代训练\n",
      "第52次迭代结束\n",
      "开始第53次迭代训练\n",
      "第53次迭代结束\n",
      "开始第54次迭代训练\n",
      "第54次迭代结束\n",
      "开始第55次迭代训练\n",
      "第55次迭代结束\n",
      "开始第56次迭代训练\n",
      "第56次迭代结束\n",
      "开始第57次迭代训练\n",
      "第57次迭代结束\n",
      "开始第58次迭代训练\n",
      "第58次迭代结束\n",
      "开始第59次迭代训练\n",
      "第59次迭代结束\n",
      "开始第60次迭代训练\n",
      "第60次迭代结束\n",
      "开始第61次迭代训练\n",
      "第61次迭代结束\n",
      "开始第62次迭代训练\n",
      "第62次迭代结束\n",
      "开始第63次迭代训练\n",
      "第63次迭代结束\n",
      "开始第64次迭代训练\n",
      "第64次迭代结束\n",
      "开始第65次迭代训练\n",
      "第65次迭代结束\n",
      "开始第66次迭代训练\n",
      "第66次迭代结束\n",
      "开始第67次迭代训练\n",
      "第67次迭代结束\n",
      "开始第68次迭代训练\n",
      "第68次迭代结束\n",
      "开始第69次迭代训练\n",
      "第69次迭代结束\n",
      "开始第70次迭代训练\n",
      "第70次迭代结束\n",
      "开始第71次迭代训练\n",
      "第71次迭代结束\n",
      "开始第72次迭代训练\n",
      "第72次迭代结束\n",
      "开始第73次迭代训练\n",
      "第73次迭代结束\n",
      "开始第74次迭代训练\n",
      "第74次迭代结束\n",
      "开始第75次迭代训练\n",
      "第75次迭代结束\n",
      "开始第76次迭代训练\n",
      "第76次迭代结束\n",
      "开始第77次迭代训练\n",
      "第77次迭代结束\n",
      "开始第78次迭代训练\n",
      "第78次迭代结束\n",
      "开始第79次迭代训练\n",
      "第79次迭代结束\n",
      "开始第80次迭代训练\n",
      "第80次迭代结束\n",
      "开始第81次迭代训练\n",
      "第81次迭代结束\n",
      "开始第82次迭代训练\n",
      "第82次迭代结束\n",
      "开始第83次迭代训练\n",
      "第83次迭代结束\n",
      "开始第84次迭代训练\n",
      "第84次迭代结束\n",
      "开始第85次迭代训练\n",
      "第85次迭代结束\n",
      "开始第86次迭代训练\n",
      "第86次迭代结束\n",
      "开始第87次迭代训练\n",
      "第87次迭代结束\n",
      "开始第88次迭代训练\n",
      "第88次迭代结束\n",
      "开始第89次迭代训练\n",
      "第89次迭代结束\n",
      "开始第90次迭代训练\n",
      "第90次迭代结束\n",
      "开始第91次迭代训练\n",
      "第91次迭代结束\n",
      "开始第92次迭代训练\n",
      "第92次迭代结束\n",
      "开始第93次迭代训练\n",
      "第93次迭代结束\n",
      "开始第94次迭代训练\n",
      "第94次迭代结束\n",
      "开始第95次迭代训练\n",
      "第95次迭代结束\n",
      "开始第96次迭代训练\n",
      "第96次迭代结束\n",
      "开始第97次迭代训练\n",
      "第97次迭代结束\n",
      "开始第98次迭代训练\n",
      "第98次迭代结束\n",
      "开始第99次迭代训练\n",
      "第99次迭代结束\n"
     ]
    }
   ],
   "source": [
    "# 开始训练 LFM 模型\n",
    "P, Q, ess = LFM_grad_desc( R, K, theta, alpha, lamda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过训练的 P和 Q 计算出预测评分矩阵\n",
    "pred_R = np.dot( P, Q.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  5.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  3.5 ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]]\n",
      "[[1.81997774 3.70500913 2.7721907  ... 2.10210662 3.20071993 3.15244949]\n",
      " [1.72248078 3.14125531 2.82133126 ... 1.97295651 3.07101939 2.84086225]\n",
      " [1.91680913 3.51910495 3.01914877 ... 2.07485048 3.63611049 3.05844255]\n",
      " ...\n",
      " [1.52083798 2.9100801  2.10877275 ... 1.45359534 2.79854783 2.44302023]\n",
      " [1.7574392  3.17843482 3.13337157 ... 2.03826032 3.11554479 2.79861946]\n",
      " [1.47630212 3.02658913 2.1456578  ... 1.35490348 2.70056746 2.29415755]]\n"
     ]
    }
   ],
   "source": [
    "# 查看原始评分矩阵\n",
    "print(R)\n",
    "\n",
    "# 查看预测评分矩阵\n",
    "print(pred_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.04522668 1.3098039  1.24531841 0.81362585 1.52680733]\n",
      " [1.01876636 1.27224132 0.88063744 1.03252428 1.22234485]\n",
      " [1.16098847 0.89530005 1.17037215 1.56074187 1.22290952]\n",
      " [1.23971922 1.03274127 1.16247168 1.18100652 1.44816497]\n",
      " [1.26048827 1.17150389 1.49481865 1.33771371 0.77582581]\n",
      " [1.32194358 1.07023759 1.51013497 1.22686157 1.04366229]\n",
      " [1.37788385 1.10266049 1.68152439 1.29946278 1.37681107]\n",
      " [1.3403602  1.37195972 1.16594337 1.36094134 1.75939818]\n",
      " [1.12573858 1.09733649 0.95856618 1.39120172 1.07279106]\n",
      " [1.09496704 0.97232826 1.31498484 1.26774867 1.12240342]\n",
      " [1.23585391 1.06813548 1.80357974 1.1588287  1.63855461]\n",
      " [1.44503199 1.20576606 1.5569306  1.17549262 1.30078182]\n",
      " [1.16273536 1.21696437 1.46575865 1.32124267 1.46035303]\n",
      " [1.47634636 1.17576498 0.77171321 0.78777255 1.33693378]\n",
      " [1.07751382 0.41127439 0.8667306  1.09307883 0.6896588 ]\n",
      " [0.7259751  1.61943646 1.60243843 1.28394903 1.16272287]\n",
      " [0.91150966 1.19914103 1.00925471 1.71029864 1.34552774]\n",
      " [1.45047092 1.09241631 0.70087098 1.39897912 1.09370895]\n",
      " [0.96270381 1.58884796 0.76300709 1.42597194 1.46825685]\n",
      " [1.37097698 1.3025455  1.5034427  1.3337454  1.14406062]\n",
      " [1.5577516  1.30422306 1.45184158 1.81334608 1.26478377]\n",
      " [1.30936242 1.52192526 1.08093431 0.79410898 0.77755975]\n",
      " [1.36880055 1.63192891 1.16289981 1.78933449 1.59749206]\n",
      " [1.09037271 1.57493609 1.48320888 1.23507449 1.26666921]\n",
      " [1.17376258 1.01983086 1.01337159 1.40959158 1.49927751]\n",
      " [1.45400229 1.20298902 1.11791392 1.65829112 1.19510106]\n",
      " [1.1068736  1.28684691 1.27183884 0.52130659 1.22024085]\n",
      " [1.31642612 0.84029944 1.40943921 1.48191876 1.34362076]\n",
      " [1.21411689 1.06416911 1.12376736 0.96648885 1.03167827]\n",
      " [1.52450177 1.21385718 0.73723898 1.18514357 1.56238909]\n",
      " [1.54596711 0.81984224 1.5059752  0.86140852 1.05793872]\n",
      " [1.10746879 1.45858363 1.17106148 1.37105093 1.33610894]\n",
      " [1.25102327 0.36834903 1.2912892  0.70054724 0.74097944]\n",
      " [1.09621046 1.6727465  1.17450004 1.59506622 1.58002594]\n",
      " [1.42537864 1.04702039 1.38440981 1.77799659 1.14983378]\n",
      " [1.37152369 1.41826804 1.558832   1.14715654 1.01126716]\n",
      " [1.69628277 1.47390413 1.23689472 0.98385268 1.19932735]\n",
      " [0.92155472 1.04083633 1.00014271 0.92834837 1.05648363]\n",
      " [1.14506199 0.93166369 1.21101763 1.54554399 0.98083147]\n",
      " [1.54828107 1.34057468 1.53679427 1.26767062 0.76769159]\n",
      " [1.71943089 1.60732717 1.10938827 1.34743364 1.71004794]\n",
      " [1.30281387 1.51734974 1.47657646 0.88127227 0.91553063]\n",
      " [1.34852856 1.19062426 1.12180737 1.33526787 0.56805431]\n",
      " [0.85157596 1.31729342 1.06608326 1.18480245 1.05062502]\n",
      " [1.15060141 0.88979364 1.49504929 1.30672558 1.61541109]\n",
      " [0.99753394 0.79366258 1.53315355 0.90017321 1.40236632]\n",
      " [1.52929784 1.0762208  1.18458265 1.65935095 1.08990097]\n",
      " [1.62843587 1.01116138 1.07811997 1.24489699 0.79326492]\n",
      " [0.81159468 1.11800674 1.23203183 0.76624324 1.50570972]\n",
      " [1.3369715  1.28525827 0.71034788 0.8250292  1.52677109]\n",
      " [1.21706878 1.30693878 1.29108882 0.57292946 0.95656946]\n",
      " [0.86408328 1.20231423 1.0798878  1.6434301  0.94103928]\n",
      " [1.53216399 1.61331974 0.9762189  1.70163299 1.10259895]\n",
      " [0.72185228 1.19795069 1.17967949 1.10107869 0.97386126]\n",
      " [0.74012377 1.42939182 0.93740605 1.48593486 1.02491401]\n",
      " [1.38562776 1.04850885 1.10384983 1.38801341 1.47750918]\n",
      " [1.07088131 1.28164734 1.00981689 0.99688576 0.87099222]\n",
      " [1.58012032 1.2327673  1.13357093 1.35172293 0.75768643]\n",
      " [1.05524883 1.20576811 0.93307508 1.35528587 1.30527012]\n",
      " [1.17851963 1.3836971  1.00225211 0.82506327 1.24424219]\n",
      " [0.84903158 0.65238311 0.62715091 1.26484023 0.97185943]\n",
      " [1.15103298 1.09028059 1.05255872 1.54745214 1.46092363]\n",
      " [0.91410731 1.73562259 0.89634839 1.26969605 1.38254286]\n",
      " [0.92683481 1.516531   0.86117667 1.42062869 0.79862443]\n",
      " [1.14881526 1.79838597 1.23222121 1.03063668 1.83500217]\n",
      " [1.29046367 1.06120726 0.6206515  0.72765917 1.42891452]\n",
      " [0.83453154 1.06370235 0.97632833 1.39480188 1.44605262]\n",
      " [1.6740003  1.05953911 1.28917668 1.35894569 0.78796859]\n",
      " [0.71247884 1.09538152 1.12477235 1.22733846 1.43667521]\n",
      " [0.97622595 0.7970674  1.39921647 1.1134244  1.34863265]\n",
      " [1.21012721 1.75462902 1.351819   1.2056633  1.15413979]\n",
      " [1.45603668 1.0474396  1.0267738  1.25436788 1.18763214]\n",
      " [0.63814179 0.57958761 1.08132126 1.17878051 1.25132464]\n",
      " [0.99820104 1.50083119 0.95271421 1.16901647 1.07282258]\n",
      " [0.46168962 0.62609459 1.37748458 1.24709138 1.16301913]]\n",
      "====================================================\n",
      "[[0.32465942 0.23836012 0.0568128  0.41888384 0.49571761]\n",
      " [0.68939278 0.30998601 0.9390738  0.23497249 0.79760616]\n",
      " [0.5656744  0.93494749 0.15064237 0.80667229 0.07362272]\n",
      " ...\n",
      " [0.81050743 0.39250874 0.12974141 0.18330507 0.28171337]\n",
      " [0.86824199 0.18189055 0.17802408 0.86739479 0.73849384]\n",
      " [0.79261696 0.29005257 0.14196625 0.32656529 0.98347573]]\n"
     ]
    }
   ],
   "source": [
    "# 查看训练后的 P 和 Q 矩阵\n",
    "print(P)\n",
    "print(\"====================================================\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFM模型评测指标\n",
    "# RMSE 和 MAE\n",
    "\n",
    "def calc_evaluation(R, pred_R):\n",
    "    mae_sum = 0.0\n",
    "    rmse_sum = 0.0\n",
    "    # 基本维度参数定义\n",
    "    M = R.shape[0]\n",
    "    N = R.shape[1]\n",
    "    T = 0\n",
    "    \n",
    "    for user in range(M):\n",
    "        for item in range(N):\n",
    "            if R[user, item] > 0:\n",
    "                T += 1\n",
    "                ess = R[user, item] - pred_R[user, item]\n",
    "                mae_sum += abs(ess)\n",
    "                rmse_sum += ess**2\n",
    "    \n",
    "    # 计算总的 MAE 指标\n",
    "    MAE = mae_sum / T\n",
    "    # Root Mean Square Error RMSE\n",
    "    RMSE = np.sqrt(rmse_sum / T)\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the MAE of LFM: 0.6513055618392573\n",
      "the RMSE OF LFM: 0.8312878250829656\n"
     ]
    }
   ],
   "source": [
    "MAE, RMSE = calc_evaluation(R, pred_R)\n",
    "print(\"the MAE of LFM:\", MAE)\n",
    "print(\"the RMSE OF LFM:\", RMSE) # 迭代次数为 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
